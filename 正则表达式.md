# 正则表达式

~~~markdown
并不是Python独有的---是一套引擎，用于做字符串的检索

1. 网络爬虫爬取数据应用到正则表达式
2. 正则表达式：起源于Unix---awk，grep，egrep
~~~

* 正则表达式的基本概念

~~~markdown
是一种小型的，高度专业化的编程语言
它内嵌在Python，通过re模块来实现的
1. 可以为想要匹配的相应字符串指定查找规则
2. 可以利用re模块以多种方式修改或查找字符串

运行原理：
正则表达式被编译成一列写的字节码，后由c编写的匹配引擎进行执行

注意：
正则表达式语言相对小型，受限（功能强大，但是并非所有的字符串处理都可以使用正则表达式）
~~~

* re模块

~~~markdown
1. findall（正则表达式，目标字符串）
		返回一个列表，列表中是符合要求的字符串
~~~

* 字符串的匹配

~~~markdown
1. 普通字符
		大多数的字母和字符都可以进行自身匹配
2. 元字符
		. ^ * $ ? + {} () \ | []
~~~

* 元字符

~~~markdown
1. []
		a. 常用来指定一个字符集
		b. 可以表示一个范围
		c. []内的元字符不起作用，只表示普通字符
		d. [^n] 除了n（范围）以外的字符串
2. ^ 
		通常用来匹配行首
3. $ 
		通常用来比配行尾
4. \ （反斜杠）
		反斜杠后面可以加不同的字符表示不同的特殊含义
		\d:匹配任何十进制数
		\D:匹配任何非十进制数
		\s:匹配任何空白字符：\t \n \r
		\S:同上取反
		\w:匹配任何字母数字字符
		\W:同上取反
		
		\可以转义，用于取消元字符，转义成普通字符
5. {n}
		重复
6. * 
		指定一个字符可以被比配零次或多次（尽可能多的取值）
7. +
		表示匹配一次或多次
8. .
		表示匹配除了换行符以外的任何字符
		不匹配\n
9. ？
		指定匹配一次或零次
		
		+，*---尽可能多的匹配数据---贪婪模式
		？---尽可能少的匹配数据----非贪婪模式
10. {m,n}
		m,n,是十进制数
		表示最少重复m次，最多重复n次
		{0,}--*
		{1,}--+
		{0,1}---?
~~~

* 正则表达式的使用

~~~markdown
先编译后解释
1. re模块提供了一个正则表达式的引擎接口，可以将正则表达式编译成对象来进行匹配
2. 编译正则：
		re.compile
3. re.compile(正则表达式)
		可以接收标志参数（可选参数）
~~~

---

### 正则对象的方法

| 方法         | 作用                                       |
| ---------- | ---------------------------------------- |
| match（）    | 决定re是否在字符刚开始的位置匹配（匹配行首）                  |
| search()   | 扫描字符串，找到这个re匹配的位置                        |
| findall（）  | 找到re匹配的所有字符串，并返回一个列表                     |
| finditer() | 找到re匹配的所有字符串，并返回一个可迭代对象，每一个元素都是一个Match对象 |

~~~markdown
如果匹配到了字符串，则返回Match object，如果找不到对应字符串则直接返回None

import re
# match()
rule=re.compile('baizhi')
print(rule.match('baizhipython'))

# search()
print(rule.search('abcbaizhi'))

# findall()
print(rule.findall('baizhiBaizhi'))

# finditer()
print('==============================')
a=rule.finditer('baizhi1baizhi2baizhi3')
for i in a:
    print(i)
~~~

* Match object 

~~~markdown
1. group（）
		返回re比配的字符串
2. start（）
		返回匹配开始的位置
3. end()
		返回匹配结束的位置
4. span()
		返回一个元组：（开始，结束）的位置
~~~

~~~python
import re
s='baizhibaizhi'
rule=re.compile('baizhi')
#返回match object
m=rule.finditer(s)
for i in m:
    print(i.group())
print('===========')
m2=rule.match('baizhiPython')
print(m2.start(),m2.end(),m2.span())
~~~

* re模块的函数

~~~markdown
1. findall（）
		根据正则表达式找到匹配的所有字符串，返回一个列表
2. sub（正则，新字符串，原字符串）
		替换字符串
3. subn（正则，新字符串，原字符串）
		替换字符串，并返回替换的次数
4. split（）
		分割字符串

正则对象的方法和re模块中的顶层方法用法一样
~~~

~~~python
import re
# findall()

s='baizhi'
print(re.findall('baizhi',s))

rule=re.compile('baizhi')
print(rule.findall(s))

# sub()

s2='baizhiPythonbaizhiJava'
#print(s2.replace(s2,'hehe'),s2)
print(re.sub('baizhi','hehe',s2))
print(re.subn('baizhi','hehe',s2))


print('===============')
# split

s='123-456-789'
# print(s.split('-'))
print(re.split('-',s))

s='123*456+987&234)987^3324'
print(re.split('[*,+,),^,&]',s))
~~~

* 编译标识---flag

| 标识          | 含义                                                         |
| ------------- | ------------------------------------------------------------ |
| DOTALL，S     | 使 . 匹配包括换行符在内的所有字符                            |
| IGNORECASE，I | 使得匹配对大小写不敏感                                       |
| MULTILINE，M  | 多行匹配，影响^和$                                           |
| VERBOSE,  X   | 能够使用re的verbose状态，使re被组织的更清晰易懂(正则表达式可以多行书写) |



~~~python
import  re

#S
print(re.findall('baizhi.com','baizhi\ncom',re.S))
print(re.findall('baizhi.com','baizhi\ncom'))

# I  :大小写不敏感
print(re.findall('baizhi','Baizhibaizhi'))
print(re.findall('baizhi','Baizhibaizhi',re.I))

# M  :多行匹配，影响^ $

s="""
tiger
monkey
python
panda
elephan
"""
print(re.findall('^monkey$',s,re.M))

# X: 清晰易懂

rule="""
010
-?
\d*
"""

print(re.findall(rule,'010-12345678',re.X))
~~~

* 分组： （）

~~~markdown
1. 只显示分组后的内容
2. |： 表示或
~~~

~~~python
import re

s1='123@qq.com'
s2='123@163.com'
s3='123@zpark.cn'
s4='123@hehe.org'

rule='\w+@\w+\.(com|cn)'
print(re.findall(rule,s1))
print(re.findall(rule,s2))
print(re.findall(rule,s3))
print(re.findall(rule,s4))

s="""
Python hehe
a=hehe
a=Python a=monkey
baizhi
"""

# 取所有a=??的字符串，并把等号后面的值取出来

print(re.findall('a=(\w*)',s))
~~~

---

### 爬虫练习

~~~Markdown
web crawler  ---网络爬虫
1. 是一种按照一定的规则，自动的抓取万维网信息的程序或脚本
		蚂蚁，自动索引，蠕虫
2. 需求：
		下载百度贴吧中的图片
		
项目：
需求分析
编码
~~~

~~~python
# 找<img  src="https://????.jpg">   bpic="https://????.jpg">  data-original="https://????.jpg">
import re,urllib.request as u

def getHtml(url):
    # 通过urlopen（）获取当前的网页
    page=u.urlopen(url)
    # 将网页源码以字符串的形式读取出来
    html=page.read() # html---二进制字符串，注意解码---decode（）
    return html

def getImg(html):
    # 制定正则表达式
    rule='src="(http.*\.jpg)"'
    # 编译正则
    img_rule=re.compile(rule)
    #从html字符串中获取符合要求的图片路径
    img_list=img_rule.findall(html.decode())

    #下载并保存---默认保存到当前路径
    count=0
    for i in img_list:
        u.urlretrieve(i,'%d.jpg'%count)
        count+=1
html=getHtml('http://tieba.baidu.com/p/2125402523#!/l/p1')

getImg(html)
~~~



